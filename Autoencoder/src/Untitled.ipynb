{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n",
      "Total number of examples 24300\n",
      "Train number of examples 19440\n",
      "Test number of examples 4861\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_save_checkpoints_steps': 400, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_id': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000BDCCAC8>, '_save_summary_steps': 100, '_environment': 'local', '_master': '', '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': None}\n",
      "configuring early stopping\n",
      "WARNING:tensorflow:From C:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\monitors.py:267: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "Fit will start...\n",
      "Using 4 cores.\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f635ac4bf612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m#classifier = learn.SKCompat(classifier) # For Sklearn compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m \u001b[0mgrid_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fit is finish...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    559\u001b[0m                                          n_candidates * len(cv)))\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\birinhos\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'params'"
     ]
    }
   ],
   "source": [
    "#from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def get_model_dir(name,erase):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    return model_dir\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "#save init (?)\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#builder = tf.saved_model.builder.SavedModelBuilder(\"./model\")\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(tf.VERSION)\n",
    "\n",
    "df = pd.read_csv('../NNNormalizeData-out.csv')\n",
    "\n",
    "np.random.seed(42) # always shuffle the same way \n",
    "df = df.reindex(np.random.permutation(df.index)) # shuffle examples \n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "inputs = []\n",
    "target = []\n",
    "\n",
    "y=0;    \n",
    "for x in df.columns:\n",
    "    if y != 35 :\n",
    "        inputs.append(x)\n",
    "    else :\n",
    "        target.append(x)\n",
    "    y+=1\n",
    "\n",
    "total_inputs,total_output = df.as_matrix(inputs).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "\n",
    "train_inputs, test_inputs, train_output, test_output = train_test_split(total_inputs, total_output, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Total number of examples %d\" %(total_inputs.shape[0]+1))\n",
    "print(\"Train number of examples %d\" %(train_inputs.shape[0]+1))\n",
    "print(\"Test number of examples %d\" %(test_inputs.shape[0]+1))\n",
    "\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=train_inputs.shape[1])]\n",
    "#target_column = [tf.contrib.layers.real_valued_column(\"output\", dimension=train_output.shape[1])]\n",
    "model_dir = get_model_dir('ModelSave',True)\n",
    "\n",
    "training_steps = 20000\n",
    "save_checkpoints_steps=400 # used to run the early stopping monitor \n",
    "early_stopping_rounds=2000   # after 50 SPETS if \"loss\" doesn't improve stop the train\n",
    "batch_size=(train_inputs.shape[0]+1)/10 # train number of examples / 10 - 10 batch = 1 epoch\n",
    "\n",
    "# The hyperparameters specified here will be searched.  Every combination.\n",
    "\n",
    "\n",
    "classifier = learn.DNNClassifier(hidden_units=[100, 50, 20], n_classes=5\n",
    "                                 ,model_dir= model_dir\n",
    "                                 #,optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                 #     learning_rate=0.01)\n",
    "                                 #     l1_regularization_strength=0.001\n",
    "                                 #     )\n",
    "                                 ,config=tf.contrib.learn.RunConfig(save_checkpoints_steps=save_checkpoints_steps\n",
    "                                                                    ,save_checkpoints_secs=None)\n",
    "                                 ,feature_columns=feature_columns)\n",
    "\n",
    "\n",
    "#early stopping using validation monitor \n",
    "print(\"configuring early stopping\")\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x=test_inputs,\n",
    "    y=test_output,\n",
    "    #every_n_steps=200,  # when to run the monitor - not working - forcing with save_checkpoints_steps\n",
    "    early_stopping_metric=\"loss\",         #\"accuracy\" of \"loss\"\n",
    "    early_stopping_metric_minimize=True,     #False Maximize accuracy (True is minimize applied to loss)  \n",
    "    early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "print(\"Fit will start...\")\n",
    "# Startup grid search\n",
    "threads = multiprocessing.cpu_count()\n",
    "print(\"Using {} cores.\".format(threads))\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "    ,'batch_size': [64, 128, 256, batch_size]\n",
    "    #,'steps': [training_steps]\n",
    "}\n",
    "\n",
    "grid_classifier = GridSearchCV(classifier,verbose=True, n_jobs=threads,scoring='accuracy', \n",
    "                             param_grid=param_grid ,fit_params={'monitor':validation_monitor})\n",
    "\n",
    "\n",
    "\n",
    "#classifier = learn.SKCompat(classifier) # For Sklearn compatibility\n",
    "grid_classifier.fit(train_inputs, train_output)\n",
    "print(\"Fit is finish...\")\n",
    "\n",
    "\n",
    "#print (classifier.get_variable_names()) \n",
    "\n",
    "#Save Model into saved_model.pbtxt file (possible to Load in Java)\n",
    "#tfrecord_serving_input_fn = tf.contrib.learn.build_parsing_serving_input_fn(layers.create_feature_spec_for_parsing(feature_columns))  \n",
    "#classifier.export_savedmodel(export_dir_base=\"test\", serving_input_fn = tfrecord_serving_input_fn,as_text=True)\n",
    "\n",
    "\n",
    "# Measure accuracy\n",
    "pred = list(classifier.predict(test_inputs, as_iterable=True))\n",
    "#pred = list(classifier.predict(test_inputs))\n",
    "score = metrics.accuracy_score(test_output, pred)\n",
    "print(\"Final score: {}\".format(score))\n",
    "\n",
    "accuracy_score = classifier.evaluate(x=test_inputs,\n",
    "                                     y=test_output)[\"accuracy\"]\n",
    "\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    "\n",
    "# test individual samples \n",
    "sample_1 = np.array( [[0.37671986791414125,0.28395908337619136,-0.0966095873607713,-1.0,0.06891621389763203,-0.09716678086712205,0.726029084013637,4.984689881073479E-4,-0.30296253267499107,-0.16192917054985334,0.04820256230479658,0.4951319883569152,0.5269983894210499,-0.2560313828048315,-0.3710980821053321,-0.4845867212612598,-0.8647234314469595,-0.6491591208322198,-1.0,-0.5004549422844073,-0.9880910165770813,0.5540293108747256,0.5625990251930839,0.7420121698556554,0.5445551415657979,0.4644276850235627,0.7316976292340245,0.636690006814346,0.16486621649984112,-0.0466018967678159,0.5261100063227044,0.6256168612312738,-0.544295484930702,0.379125782517193,0.6959368575211544]], dtype=float)\n",
    "sample_2 = np.array( [[1.0,0.7982741870963959,1.0,-0.46270838239235024,0.040320274521029376,0.443451913224413,-1.0,1.0,1.0,-1.0,0.36689718911339564,-0.13577379160035796,-0.5162916256414466,-0.03373651520104648,1.0,1.0,1.0,1.0,0.786999801054777,-0.43856035121103853,-0.8199093927945158,1.0,-1.0,-1.0,-0.1134921695894473,-1.0,0.6420892436196663,0.7871737734493178,1.0,0.6501788845358409,1.0,1.0,1.0,-0.17586627413625022,0.8817194210401085]], dtype=float)\n",
    "\n",
    "pred = list(classifier.predict(sample_2, as_iterable=True))\n",
    "print(\"Prediction for sample_2 is:{} \".format(pred))\n",
    "\n",
    "pred = list(classifier.predict_proba(sample_2, as_iterable=True))\n",
    "print(\"Prediction for sample_2 is:{} \".format(pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
